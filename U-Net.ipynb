{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH30qOGezKf6"
   },
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjoqJS7dm4cC"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8dAs-AcnVc8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxF7pqnynXNZ"
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5qZ_LfsnZpW"
   },
   "outputs": [],
   "source": [
    "# the original file was implemented in Google Colab to take advantage of the free GPU \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfxlNgLxnxzP"
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    img_data_gen = ImageDataGenerator(rotation_range=20, \n",
    "                                      width_shift_range=20,\n",
    "                                      height_shift_range=20,\n",
    "                                      zoom_range=0.5,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True, \n",
    "                                      brightness_range=(0.8, 1.2),  \n",
    "                                      shear_range=20,  \n",
    "                                      channel_shift_range=20, \n",
    "                                      fill_mode='reflect')\n",
    "\n",
    "    mask_data_gen = ImageDataGenerator(rotation_range=20,\n",
    "                                       width_shift_range=20,\n",
    "                                       height_shift_range=20,\n",
    "                                       zoom_range=0.5,\n",
    "                                       shear_range=20, \n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f18vVSk5n1O7"
   },
   "outputs": [],
   "source": [
    "# it is necessary modify the class CustomDataset to create a flow of pairs of images for the training\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "  \"\"\"\n",
    "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
    "\n",
    "    3 main methods:\n",
    "      - __init__: save dataset params like directory, filenames..\n",
    "      - __len__: return the total number of samples in the dataset\n",
    "      - __getitem__: return a sample from the dataset\n",
    "\n",
    "    Note: \n",
    "      - the custom dataset return a single sample from the dataset. Then, we use \n",
    "        a tf.data.Dataset object to group samples into batches.\n",
    "      - in this case we have a different structure of the dataset in memory. \n",
    "        We have all the images in the same folder and the training and validation splits\n",
    "        are defined in text files.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[160, 160]):\n",
    "    if which_subset == 'training':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
    "    elif which_subset == 'validation':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n",
    "    \n",
    "    with open(subset_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "    \n",
    "    subset_filenames = []\n",
    "    for line in lines:\n",
    "      subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # Read Image\n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    if curr_filename[:6]==\"Roseau\":\n",
    "        img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\n",
    "    else:\n",
    "        img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n",
    "    mask = Image.open(os.path.join(self.dataset_dir, 'Annotations', curr_filename + '.png'))\n",
    "\n",
    "    # Resize image and mask\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "\n",
    "    if self.which_subset == 'training':\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        # Perform data augmentation\n",
    "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
    "        # and we can apply it to the image using apply_transform\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
    "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
    "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
    "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
    "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
    "            # from [0, 1] to {0, 1}\n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            # recover original class\n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "\n",
    "\n",
    "    return img_arr, np.float32(out_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igeFAG3In5Yu"
   },
   "outputs": [],
   "source": [
    "# Tutorial parameters\n",
    "img_size = (160, 160)\n",
    "img_h=160\n",
    "img_w=160\n",
    "num_classes = 3\n",
    "batch_size = 32\n",
    "\n",
    "# No preprocessing functions are used\n",
    "\n",
    "dataset = CustomDataset('/content/drive/My Drive/NeuralNetworks/Dataset', 'training', \n",
    "                        img_generator=img_data_gen, mask_generator=mask_data_gen)\n",
    "dataset_valid = CustomDataset('/content/drive/My Drive/NeuralNetworks/Dataset', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCxcP93BqfUa"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.batch(32)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEWmY1Pmqx0p"
   },
   "outputs": [],
   "source": [
    "# Let's test data generator\n",
    "# -------------------------\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Assign a color to each class\n",
    "evenly_spaced_interval = np.linspace(0, 1, 2) # 3 classes\n",
    "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "\n",
    "iterator = iter(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zjo-gqN8q0_K"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]   # First element\n",
    "augmented_img = augmented_img  # denormalize\n",
    "\n",
    "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
    "\n",
    "print(np.unique(target))\n",
    "\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "for i in range(1, 3): #per 3 classi\n",
    "  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
    "\n",
    "ax[0].imshow(np.uint8(augmented_img))\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpoPPYY4p3Cn"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GSiE72erlb3"
   },
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Here we define the intersection over union for each class in the batch.\n",
    "# Then we compute the final iou as the mean over classes\n",
    "def meanIoU(y_true, y_pred):\n",
    "    # get predicted class from softmax\n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(1,3): # exclude the background class 0\n",
    "      # Get prediction and target related to only a single class (i)\n",
    "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "      intersection = tf.reduce_sum(class_true * class_pred)\n",
    "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "    \n",
    "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "      per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "metrics = ['accuracy', meanIoU]\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wr5DbrIwdQbn"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/My\\ Drive/NeuralNetworks/multiclass_segmentation_experiments/ --port 6009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi35E5R_sBbJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'drive/My Drive/NeuralNetworks/', 'multiclass_segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'U-Net'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(dataset),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid), \n",
    "          callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net_Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
